{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-10-15T15:17:12.868551Z",
     "iopub.status.busy": "2024-10-15T15:17:12.868054Z",
     "iopub.status.idle": "2024-10-15T15:17:18.103102Z",
     "shell.execute_reply": "2024-10-15T15:17:18.102347Z",
     "shell.execute_reply.started": "2024-10-15T15:17:12.868519Z"
    },
    "id": "KKMHFvHk8ubA",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gaen/Documents/codespace-gaen/Ts-master\n"
     ]
    }
   ],
   "source": [
    "!pip --quiet install pytorch-warmup\n",
    "#%cd /mnt/workspace/shell/\n",
    "%cd /home/gaen/Documents/codespace-gaen/Ts-master\n",
    "#这个cd就是我家里主机上就这样\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:15:55.053826Z",
     "iopub.status.busy": "2024-10-15T11:15:55.053454Z",
     "iopub.status.idle": "2024-10-15T11:16:00.094319Z",
     "shell.execute_reply": "2024-10-15T11:16:00.093687Z",
     "shell.execute_reply.started": "2024-10-15T11:15:55.053799Z"
    },
    "id": "orio-YPdlbsf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output \n",
    "!pip --quiet install pytorch_spiking pytorch_lightning #pytorch_forecasting \n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-10-15T15:16:37.201927Z",
     "iopub.status.busy": "2024-10-15T15:16:37.201562Z",
     "iopub.status.idle": "2024-10-15T15:16:43.978544Z",
     "shell.execute_reply": "2024-10-15T15:16:43.978017Z",
     "shell.execute_reply.started": "2024-10-15T15:16:37.201904Z"
    },
    "id": "z68p_q4eISQP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules import TransformerEncoder, TransformerEncoderLayer, LayerNorm\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import pytorch_spiking\n",
    "import pytorch_warmup as warmup\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : Cuda libraries were not detected on the system or could not be loaded ; using cpu only mode\n"
     ]
    }
   ],
   "source": [
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from models_s4.s4.s4 import S4Block as S4  # Can use full version instead of minimal S4D standalone below\n",
    "from models_s4.s4.s4d import S4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:16:13.025485Z",
     "iopub.status.busy": "2024-10-15T11:16:13.024992Z",
     "iopub.status.idle": "2024-10-15T11:16:13.031042Z",
     "shell.execute_reply": "2024-10-15T11:16:13.030512Z",
     "shell.execute_reply.started": "2024-10-15T11:16:13.025461Z"
    },
    "id": "FUcYIRwMIVPV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "  \"plots\": {\n",
    "        \"show_plots\": False,\n",
    "        \"xticks_interval\": 1200,\n",
    "        \"color_actual\": \"#001f3f\",\n",
    "        \"color_train\": \"#3D9970\",\n",
    "        \"color_val\": \"#0074D9\",\n",
    "        \"color_test\": \"#FF4136\",\n",
    "        \"color_pred_train\": \"#3D9970\",\n",
    "        \"color_pred_val\": \"#0074D9\",\n",
    "        \"color_pred_test\": \"#FF4136\",\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"train_split_size\": 0.80,\n",
    "        \"input_window\": 30,\n",
    "        \"output_window\": 10,\n",
    "        \"train_batch_size\": 3,\n",
    "        \"eval_batch_size\": 1,\n",
    "        \"scaler\": \"normal\"\n",
    "    }, \n",
    "    \"model_transformer\": {\n",
    "        \"feature_size\": 250,\n",
    "        \"nhead\": 10,\n",
    "        \"num_layers\": 2,\n",
    "        \"dropout\": 0.2,\n",
    "        \"out_features\": 1,\n",
    "        \"init_range\": 2, #0.5\n",
    "        \"lr\": 0.0002, #0.0001,\n",
    "        \"loss\": \"dilate\"\n",
    "    },\n",
    "    \"paths\": {\n",
    "        \"drive\": {\n",
    "            \"agg_trade\": {\n",
    "                \"train\": \"/content/drive/MyDrive/IP/Repos/HFTransformer/input_data/\",\n",
    "                \"test\": \"/content/drive/MyDrive/IP/Repos/HFTransformer/input_data/\", \n",
    "            },\n",
    "            \"orderbook\": {\n",
    "                \"train\": \"/content/drive/MyDrive/IP/Repos/HFTransformer/input_data/\",\n",
    "                \"test\": \"/content/drive/MyDrive/IP/Repos/HFTransformer/input_data/\",\n",
    "            },\n",
    "            \"models\": \"/content/drive/MyDrive/IP/Repos/HFTransformer/models/\",\n",
    "            \"figures\": \"/content/drive/MyDrive/IP/Repos/HFTransformer/figures/\",\n",
    "            \"utils\": \"/content/drive/MyDrive/IP/Repos/HFTransformer/utils/\",\n",
    "        },\n",
    "        \n",
    "        \"local\": {\n",
    "            \"agg_trade\": {\n",
    "                \"train\": \"./input_data/\",\n",
    "                \"test\": \"./input_data/\", \n",
    "            },\n",
    "            \"orderbook\": {\n",
    "                \"train\": \"./input_data/\",\n",
    "                \"test\": \"./input_data/\",\n",
    "            },\n",
    "            \"models\": \"./models/\",\n",
    "            \"figures\": \"./figures/\",\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-10-15T11:16:54.024598Z",
     "iopub.status.busy": "2024-10-15T11:16:54.024211Z",
     "iopub.status.idle": "2024-10-15T11:16:54.028041Z",
     "shell.execute_reply": "2024-10-15T11:16:54.027469Z",
     "shell.execute_reply.started": "2024-10-15T11:16:54.024567Z"
    },
    "id": "uNNtAHKTjmDD",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "drive = False\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rxx4SuGIjmDE",
    "outputId": "d7848a6f-53b2-45ae-f722-26efe0efd5ea"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3H3a86TCSFb8"
   },
   "source": [
    "## Data preparation: augmenting raw financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:16:56.665337Z",
     "iopub.status.busy": "2024-10-15T11:16:56.664978Z",
     "iopub.status.idle": "2024-10-15T11:16:56.669577Z",
     "shell.execute_reply": "2024-10-15T11:16:56.669066Z",
     "shell.execute_reply.started": "2024-10-15T11:16:56.665314Z"
    },
    "id": "AGOE00q-ARLc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def augment_trade_data(df, lag, forecast_window=None):\n",
    "    '''\n",
    "    Augmenting input data.\n",
    "    '''\n",
    "    if forecast_window:\n",
    "        df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
    "        return df.iloc[forecast_window+1:,:]\n",
    "    if lag == 0:\n",
    "        return df\n",
    "    else:\n",
    "        col_name = 'log_lag'+str(lag)+'_price'\n",
    "        df[col_name] = np.log(df.price) - np.log(df.price).shift(lag)\n",
    "        return df.iloc[lag:,:]\n",
    "    \n",
    "#后续会用到 别急 就是模拟了一个正常交易的时候的延迟"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4IH7QdtjmDH"
   },
   "source": [
    "## Defining Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tuple(map(int, torch.__version__.split('.')[:2])) == (1, 11):\n",
    "    print(\"WARNING: Dropout is bugged in PyTorch 1.11. Results may be worse.\")\n",
    "    dropout_fn = nn.Dropout\n",
    "if tuple(map(int, torch.__version__.split('.')[:2])) >= (1, 12):\n",
    "    dropout_fn = nn.Dropout1d\n",
    "else:\n",
    "    dropout_fn = nn.Dropout2d\n",
    "\n",
    "\n",
    "class S4Model(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_input,\n",
    "        d_output=10,\n",
    "        d_model=256,\n",
    "        n_layers=4,\n",
    "        dropout=0.2,\n",
    "        prenorm=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.prenorm = prenorm\n",
    "        self.encoder = nn.Linear(d_input, d_model)\n",
    "        # Stack S4 layers as residual blocks\n",
    "        self.s4_layers = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        self.dropouts = nn.ModuleList()\n",
    "        for _ in range(n_layers):\n",
    "            self.s4_layers.append(\n",
    "                S4D(d_model, dropout=dropout, transposed=True, lr=min(0.001, 0.01))\n",
    "            )\n",
    "            self.norms.append(nn.LayerNorm(d_model))\n",
    "            self.dropouts.append(dropout_fn(dropout))\n",
    "        # Linear decoder\n",
    "        self.decoder = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input x is shape (B, L, d_input)\n",
    "        \"\"\"\n",
    "        x = self.encoder(x)  # (B, L, d_input) -> (B, L, d_model)\n",
    "        if torch.isnan(x).any():\n",
    "            print(\"NaN detected in 10101010 output\")\n",
    "        x = x.transpose(-1, -2)  # (B, L, d_model) -> (B, d_model, L)\n",
    "        for layer, norm, dropout in zip(self.s4_layers, self.norms, self.dropouts):\n",
    "            # Each iteration of this loop will map (B, d_model, L) -> (B, d_model, L)\n",
    "\n",
    "            z = x\n",
    "            if self.prenorm:\n",
    "                # Prenorm\n",
    "                z = norm(z.transpose(-1, -2)).transpose(-1, -2)\n",
    "\n",
    "            # Apply S4 block: we ignore the state input and output\n",
    "            z, _ = layer(z)\n",
    "\n",
    "            # Dropout on the output of the S4 block\n",
    "            z = dropout(z)\n",
    "\n",
    "            # Residual connection\n",
    "            x = z + x\n",
    "\n",
    "            if not self.prenorm:\n",
    "                # Postnorm\n",
    "                x = norm(x.transpose(-1, -2)).transpose(-1, -2)\n",
    "\n",
    "        x = x.transpose(-1, -2)\n",
    "        if torch.isnan(x).any():\n",
    "            print(\"NaN detected in -1 output\")\n",
    "        x = self.decoder(x)  # (B, d_model) -> (B, d_output)\n",
    "        if torch.isnan(x).any():\n",
    "            print(\"NaN detected in 0 output\")\n",
    "        return x\n",
    "# torch.Size([256, 64, 100])\n",
    "# torch.Size([100, 256, 36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead), \n",
    "            num_layers=num_layers\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.transformer_encoder(x)\n",
    "\n",
    "\n",
    "class S4Transformer(nn.Module):\n",
    "    def __init__(self, input_size, d_model=36, nhead=4, num_layers=3, output_size=1):\n",
    "        super(S4Transformer, self).__init__()\n",
    "        self.s4 = S4Model(\n",
    "                d_input=38,#len(features),\n",
    "                d_output=1,\n",
    "                d_model=36,\n",
    "                n_layers=3,\n",
    "                dropout=0.1,\n",
    "                prenorm=\"store_true\")\n",
    "        self.transformer_encoder = TransformerEncoderLayer(d_model, nhead, num_layers)\n",
    "        self.fc_out = nn.Linear(d_model, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x shape: [batch_size, seq_len, input_size]\n",
    "        if torch.isnan(x).any():\n",
    "            print(\"NaN detected in 1 output\")\n",
    "        x = self.s4(x)\n",
    "        if torch.isnan(x).any():\n",
    "            print(\"NaN detected in 2 output\")\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.transformer_encoder(x)\n",
    "        if torch.isnan(x).any():\n",
    "            print(\"NaN detected in 3 output\")\n",
    "        x = x.permute(1, 0, 2)\n",
    "        if torch.isnan(x).any():\n",
    "            print(\"NaN detected in 4 output\")\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        if torch.isnan(x).any():\n",
    "            print(\"NaN detected in 5 output\")\n",
    "        x = self.fc_out(x)\n",
    "        if torch.isnan(x).any():\n",
    "            print(\"NaN detected in 6 output\")\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FN1amH-62AC7"
   },
   "source": [
    "## Defining Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:17:01.650362Z",
     "iopub.status.busy": "2024-10-15T11:17:01.650007Z",
     "iopub.status.idle": "2024-10-15T11:17:01.660153Z",
     "shell.execute_reply": "2024-10-15T11:17:01.659470Z",
     "shell.execute_reply.started": "2024-10-15T11:17:01.650339Z"
    },
    "id": "-ttkn5axAQCj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    '''\n",
    "    Class for converting LOB data into model inputs.\n",
    "    '''\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x.astype(np.float32)\n",
    "        self.y = y.astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.x[idx], self.y[idx])\n",
    "\n",
    "\n",
    "def prepare_data_x(data, window_size, lag):\n",
    "    '''\n",
    "    Windows the input data for the ML models.\n",
    "    '''\n",
    "    n_row = data.shape[0] - window_size + 1\n",
    "    subset = data[:window_size]\n",
    "    subset_mean = np.mean(subset, axis=0)\n",
    "    output = np.zeros([n_row, window_size, len(subset_mean)])\n",
    "    x_mean = np.zeros([n_row, len(subset_mean)])\n",
    "    x_std = np.zeros([n_row, len(subset_mean)])\n",
    "    for idx in range(n_row):\n",
    "        subset = data[idx:idx+window_size]\n",
    "        subset_mean = np.mean(subset, axis=0)\n",
    "        subset_std = np.std(subset, axis=0) + 0.01\n",
    "        subset_norm = (subset-subset_mean)/subset_std\n",
    "        x_mean[idx,:] = subset_mean\n",
    "        x_std[idx,:] = subset_std\n",
    "        output[idx,:,:] = subset_norm\n",
    "    x_mean = np.array(x_mean)\n",
    "    x_std = np.array(x_std)\n",
    "    return output[:-lag-1], output[-1], x_mean, x_std\n",
    "\n",
    "\n",
    "def prepare_data_y(x, window_size, lag):\n",
    "    '''\n",
    "    Windows the target data for the ML models.\n",
    "    '''\n",
    "    output = np.zeros([len(x)-window_size-lag])\n",
    "    std = 1.1*np.sqrt(lag)+lag*0.01\n",
    "    for idx in range(0,len(x)-window_size-lag):\n",
    "        output[idx] = np.log(x[window_size+lag-1+idx,0]/x[window_size-1+idx,0])*10_000\n",
    "    output = output/std\n",
    "    return output\n",
    "\n",
    "\n",
    "def prepare_data(normalized_prices_train, dates_train, normalized_prices_test, dates_test, config, lag=1, plot=False):\n",
    "    '''\n",
    "    Returns input and target data.\n",
    "    '''\n",
    "    data_x, data_x_unseen, x_mean, x_std = prepare_data_x(normalized_prices_train, window_size=100, lag=lag)\n",
    "    data_y = prepare_data_y(normalized_prices_train, window_size=100, lag=lag)\n",
    "    split_index = int(data_y.shape[0]*0.8)\n",
    "    data_x_train = data_x[:split_index]\n",
    "    data_x_val = data_x[split_index:]\n",
    "    data_y_train = data_y[:split_index]\n",
    "    data_y_val = data_y[split_index:]\n",
    "\n",
    "    return split_index, data_x_train, data_y_train, data_x_val, data_y_val\n",
    "\n",
    "\n",
    "#这些就是来帮助把数据分成batch的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fydGNgID2Fsj"
   },
   "source": [
    "## Defining Custom Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:17:03.338090Z",
     "iopub.status.busy": "2024-10-15T11:17:03.337741Z",
     "iopub.status.idle": "2024-10-15T11:17:03.342106Z",
     "shell.execute_reply": "2024-10-15T11:17:03.341579Z",
     "shell.execute_reply.started": "2024-10-15T11:17:03.338068Z"
    },
    "id": "iH5GB6Lz507o",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def quantile_loss(y, y_pred, quantile):\n",
    "  '''\n",
    "  Computes quantile loss\n",
    "  Standard quantile loss as defined in the \"Training Procedure\" section of\n",
    "  the main TFT paper\n",
    "  '''\n",
    "  if quantile < 0 or quantile > 1:\n",
    "    raise ValueError(\n",
    "        'Illegal quantile value={}! Values should be between 0 and 1.'.format(\n",
    "            quantile))\n",
    "\n",
    "  prediction_underflow = y - y_pred\n",
    "  q_loss = quantile * torch.max(prediction_underflow, torch.zeros_like(prediction_underflow)) + (\n",
    "      1. - quantile) * torch.max(-prediction_underflow, torch.zeros_like(prediction_underflow))\n",
    "\n",
    "  return torch.sum(q_loss, axis=-1)\n",
    "\n",
    "\n",
    "#quantile loss在让模型有自信值很有帮助"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjErN2nj2NyY"
   },
   "source": [
    "## Defining Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:17:05.204011Z",
     "iopub.status.busy": "2024-10-15T11:17:05.203420Z",
     "iopub.status.idle": "2024-10-15T11:17:05.218381Z",
     "shell.execute_reply": "2024-10-15T11:17:05.217768Z",
     "shell.execute_reply.started": "2024-10-15T11:17:05.203987Z"
    },
    "id": "dDimPrK3SLZP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion_dict = {\"MAE\":nn.L1Loss, \"MSE\":nn.MSELoss, \"QuantileLoss\":quantile_loss}\n",
    "\n",
    "def compute_loss(labels, output, src, criterion):\n",
    "    '''\n",
    "    Computes loss\n",
    "    '''\n",
    "    if isinstance(output, torch.Tensor):\n",
    "        if len(labels.shape) != len(output.shape):\n",
    "            if len(labels.shape) > 1:\n",
    "                if labels.shape[1] == output.shape[1]:\n",
    "                    labels = labels.unsqueeze(2)\n",
    "                else:\n",
    "                    labels = labels.unsqueeze(0)\n",
    "    loss = 0\n",
    "    loss = criterion(output, labels.float())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_step(model, opt, criterion, data_loader, takes_target, device,\n",
    "                       num_targets=1, forward_params={}):\n",
    "    '''\n",
    "    Performs training of a single model. Runs through one epoch of the data.\n",
    "    '''\n",
    "    i = 0\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for src, trg in data_loader:\n",
    "        opt.zero_grad()\n",
    "        if takes_target:\n",
    "            forward_params[\"t\"] = trg.to(device)\n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "        \n",
    "        # Ensure all tensors in forward_params are on the correct device\n",
    "        # print(src.shape)\n",
    "        output = model(src,**forward_params)\n",
    "        output = output.squeeze()\n",
    "        if num_targets == 1:\n",
    "            labels = trg\n",
    "        elif num_targets > 1:\n",
    "            labels = trg[:, :, 0:num_targets]\n",
    "\n",
    "        \n",
    "        loss = compute_loss(labels, output, src, criterion[0])\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        running_loss += loss.item()\n",
    "        i += 1\n",
    "    total_loss = running_loss\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def validation(val_loader, model, criterion, device, num_targets=1):\n",
    "    '''\n",
    "    Computes the validation loss metrics.\n",
    "    '''\n",
    "    crit_losses = dict.fromkeys(criterion, 0)\n",
    "    model.eval()\n",
    "    labels = torch.Tensor(0).to(device)\n",
    "    labels_all = torch.Tensor(0).to(device)\n",
    "    output_all = torch.Tensor(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        for src, targ in val_loader:\n",
    "            output = torch.Tensor(0).to(device)\n",
    "            src = src if isinstance(src, list) else src.to(device)\n",
    "            targ = targ if isinstance(targ, list) else targ.to(device)\n",
    "            output = model(src.float())\n",
    "            output = output.squeeze()\n",
    "            output_all = torch.cat((output_all, output))\n",
    "            if num_targets == 1:\n",
    "                labels = targ\n",
    "            elif num_targets > 1:\n",
    "                labels = targ[:, :, 0:num_targets]\n",
    "            for crit in criterion:\n",
    "                loss = compute_loss(labels, output, src, crit)\n",
    "                crit_losses[crit] += loss.item()\n",
    "            labels_all = torch.cat((labels_all, labels))\n",
    "    return list(crit_losses.values())[0], output_all, labels_all\n",
    "def forecast(data_loader, model, criterion, forecast_horizon, device, num_targets=1):\n",
    "    '''\n",
    "    Forecasting\n",
    "    '''\n",
    "    crit_losses = dict.fromkeys(criterion, 0)\n",
    "    model.eval()\n",
    "    output_decoder = torch.Tensor(0).to(device)\n",
    "    labels = torch.Tensor(0).to(device)\n",
    "    labels_all = torch.Tensor(0).to(device)\n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for src, targ in data_loader:\n",
    "            if (counter % forecast_horizon) == 0:\n",
    "                src = src if isinstance(src, list) else src.to(device)\n",
    "                targ = targ if isinstance(targ, list) else targ.to(device)\n",
    "                output = model(src.float())\n",
    "                #output = output.reshape(1,-1)\n",
    "                output_decoder = torch.cat((output_decoder, output))\n",
    "                if num_targets == 1:\n",
    "                    labels = targ\n",
    "                elif num_targets > 1:\n",
    "                    labels = targ[:, :, 0:num_targets]\n",
    "                for crit in criterion:\n",
    "                    loss = compute_loss(labels, output, src, crit)\n",
    "                    crit_losses[crit] += loss.item()\n",
    "                labels_all = torch.cat((labels_all, labels))\n",
    "            counter += 1\n",
    "    return list(crit_losses.values())[0], output_decoder, labels_all\n",
    "\n",
    "\n",
    "#这些属于常规操作了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZOqAUud2UNQ"
   },
   "source": [
    "## Defining Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:17:07.215173Z",
     "iopub.status.busy": "2024-10-15T11:17:07.214814Z",
     "iopub.status.idle": "2024-10-15T11:17:07.220690Z",
     "shell.execute_reply": "2024-10-15T11:17:07.219919Z",
     "shell.execute_reply.started": "2024-10-15T11:17:07.215150Z"
    },
    "id": "uuQDDNHiFbf4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def strategy_evaluator(true, pred):\n",
    "    '''\n",
    "    Evaluates strategy regarding correct buys and sells\n",
    "    '''\n",
    "    total_buys, total_sells, total_holds = np.sum(true>0), np.sum(true<0), np.sum(true==0)\n",
    "    total_correct_buys, total_correct_sells, total_correct_holds = 0, 0, 0\n",
    "    for idx in range(len(true)):\n",
    "        for jdx in range(len(true[0])):\n",
    "            if true[idx,jdx] > 0 and pred[idx,jdx] > 0:\n",
    "                total_correct_buys += 1\n",
    "            elif true[idx,jdx] < 0 and pred[idx,jdx] < 0:\n",
    "                total_correct_sells += 1\n",
    "            elif true[idx,jdx] == 0 and pred[idx,jdx] == 0:\n",
    "                total_correct_holds += 1\n",
    "    total_correct_buys_r, total_correct_sells_r, total_correct_holds_r = (total_correct_buys/total_buys),(total_correct_sells/total_sells),(total_correct_holds/total_holds)\n",
    "    return total_correct_buys_r.round(3), total_correct_sells_r.round(3), total_correct_holds_r.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:17:09.072073Z",
     "iopub.status.busy": "2024-10-15T11:17:09.071694Z",
     "iopub.status.idle": "2024-10-15T11:17:09.083317Z",
     "shell.execute_reply": "2024-10-15T11:17:09.082774Z",
     "shell.execute_reply.started": "2024-10-15T11:17:09.072050Z"
    },
    "id": "mUp74e95PcwZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trainer(model, train_loader, validation_loader, test_loader, criterion, opt, scheduler,\n",
    "            warmup_scheduler, max_epochs, batch_size, forecast_horizon, takes_target, shuffle=False,\n",
    "            num_targets=1, plot_prediction=True, save_path='/mnt/workspace/shell/results_Transencwithlineardec'\n",
    ", LAG=0):\n",
    "    '''\n",
    "    Training method\n",
    "    '''\n",
    "    start_time = time.time()\n",
    "    \n",
    "    data_loader = DataLoader(train_loader, batch_size=batch_size, shuffle=False, sampler=None, batch_sampler=None, num_workers=10)\n",
    "    validation_data_loader = DataLoader(validation_loader, batch_size=batch_size, shuffle=False, sampler=None, batch_sampler=None, num_workers=10)\n",
    "    test_data_loader = DataLoader(test_loader, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=2)\n",
    "    forecast_data_loader = DataLoader(validation_loader, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=2)\n",
    "    \n",
    "    for epoch in range(1, max_epochs+1):\n",
    "\n",
    "        total_loss = train_step(model, opt, criterion, data_loader, takes_target, device, num_targets=num_targets)\n",
    "        val_loss = 0\n",
    "        if plot_prediction:\n",
    "            val_loss, val_values, true_values = forecast(forecast_data_loader, model, criterion, forecast_horizon=forecast_horizon,\n",
    "                                                                   device=device, num_targets=num_targets)\n",
    "            fig, ax = plt.subplots(1, 1, figsize = (18, 8))\n",
    "            ax.plot(true_values.cpu().view(-1), label='truth', alpha=0.3)\n",
    "            ax.plot(val_values.cpu().view(-1), label='forecast', alpha=0.8)\n",
    "            ax.set_xlim(left=0, right=len(true_values.cpu().view(-1)))\n",
    "            plt.show()\n",
    "        else:\n",
    "            val_loss, val_values, true_values = validation(validation_data_loader, model, criterion, device,\n",
    "                                                            num_targets=num_targets)\n",
    "            # val_loss, val_values, true_values, src_all\n",
    "        preds, trues = val_values.cpu().numpy(), true_values.cpu().numpy()#, src_all.cpu().numpy()\n",
    "\n",
    "\n",
    "        # print(f'preds {preds.shape}')\n",
    "        # print(f'trues {trues.shape}')\n",
    "\n",
    "        results = 0\n",
    "    \n",
    "            \n",
    "        r2_sklearn = r2_score(trues, preds)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        print('-' * 88)\n",
    "        print('| epoch {:3d} | {:5.2f} s | train loss {:5.5f} | val loss {:5.5f} | lr {:1.8f} | r2 sklearn: {:1.5f} | b, s, h: {:}|'.format(\n",
    "                        epoch, elapsed, total_loss, val_loss, scheduler.get_last_lr()[0], r2_sklearn, results))\n",
    "        print('-' * 88)\n",
    "        start_time = time.time()\n",
    "\n",
    "        if save_path:\n",
    "            results = {\n",
    "                    'model': 'Transencwithlineardec',\n",
    "                    'pred_len': forecast_horizon,\n",
    "                    'epoch': epoch,\n",
    "                    'train_loss': total_loss,\n",
    "                    'val_loss': val_loss,\n",
    "                    'r2_val_sklearn': r2_sklearn            \n",
    "            }\n",
    "\n",
    "            df = pd.DataFrame([results])\n",
    "            df.to_csv(os.path.join(save_path, 'results.csv'), mode='a', header=not os.path.exists(save_path), index=False)\n",
    "            save_directory = os.path.join(save_path, \"Transencwithlineardec\")\n",
    "            if not os.path.exists(save_directory):\n",
    "                os.makedirs(save_directory)\n",
    "            if r2_sklearn >0.02 :\n",
    "                torch.save(model.state_dict(), os.path.join(save_path,\"Transencwithlineardec\",f'_epoch_{epoch}_time_{time.time()}_r2_{r2_sklearn}.pt'))\n",
    "\n",
    "        with warmup_scheduler.dampening():\n",
    "            scheduler.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJ5zrDoD2X1k"
   },
   "source": [
    "## Model and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mq_67bISiIAb"
   },
   "source": [
    "## Optimal paramater search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:17:25.182203Z",
     "iopub.status.busy": "2024-10-15T11:17:25.181837Z",
     "iopub.status.idle": "2024-10-15T11:17:57.412219Z",
     "shell.execute_reply": "2024-10-15T11:17:57.411611Z",
     "shell.execute_reply.started": "2024-10-15T11:17:25.182173Z"
    },
    "id": "rq97xGiXkzPs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# date_train = 'all' \n",
    "# date_test = 'all'\n",
    "date_train = 'All_to_Sept'\n",
    "date_test = 'All_to_Sept'\n",
    "\n",
    "\n",
    "# drive = None\n",
    "# if False:\n",
    "#     if drive:\n",
    "#         agg_trade = pd.read_csv(config[\"paths\"][\"drive\"][\"agg_trade\"][\"train\"]+date_train+'/orderbook.csv')    \n",
    "#         sys.path.append(config[\"paths\"][\"drive\"][\"utils\"])\n",
    "#     else: \n",
    "#         agg_trade = pd.read_csv(config[\"paths\"][\"local\"][\"agg_trade\"][\"train\"]+date_train+'/orderbook_agg_trade_dollarvol_drop_duplicate_price.csv')\n",
    "#         agg_trade_test = pd.read_csv(config[\"paths\"][\"local\"][\"agg_trade\"][\"test\"]+date_test+'/orderbook_agg_trade_dollarvol_drop_duplicate_price.csv')\n",
    "idx = 0\n",
    "agg_trade = pd.read_csv(config[\"paths\"][\"local\"][\"agg_trade\"][\"train\"]+date_train+'/orderbook_agg_trade_dollarvol.csv')\n",
    "# agg_trade_test = pd.read_csv(config[\"paths\"][\"local\"][\"agg_trade\"][\"test\"]+date_test+'/orderbook_agg_trade_dollarvol.csv')\n",
    "agg_trade['w_midprice'] = (agg_trade['ask1']*agg_trade['askqty1']+agg_trade['bid1']*agg_trade['bidqty1'])/(agg_trade['askqty1']+agg_trade['bidqty1'])\n",
    "# total_rows = agg_trade.shape[0]\n",
    "# total_vols = agg_trade.shape[1]\n",
    "# #agg_trade['price'] = agg_trade['w_midprice']\n",
    "# # agg_trade_test = agg_trade[4_500_000:]\n",
    "# print(total_rows,total_vols)\n",
    "# orderbook = augment_trade_data(agg_trade, lag=0, forecast_window=100)\n",
    "# features = ['price', 'lag_return',\n",
    "#                 'bid1', 'bidqty1', 'bid2', 'bidqty2', 'bid3', 'bidqty3', 'bid4', 'bidqty4', 'bid5', 'bidqty5',\n",
    "#                 'bid6', 'bidqty6', 'bid7', 'bidqty7', 'bid8', 'bidqty8', 'bid9', 'bidqty9',\n",
    "#                 'ask1', 'askqty1', 'ask2', 'askqty2', 'ask3', 'askqty3', 'ask4', 'askqty4', 'ask5', 'askqty5',\n",
    "#                 'ask6', 'askqty6', 'ask7', 'askqty7', 'ask8', 'askqty8', 'ask9', 'askqty9']\n",
    "        \n",
    "# data_array =  np.array(orderbook[features][1_000_000:1_720_000])\n",
    "# data_array =  np.array(orderbook[features][:])\n",
    "# # 查看 shape\n",
    "# print(data_array.shape)\n",
    "# # 打印前 10 行（索引 0 到 9）\n",
    "# print(\"前 10 行:\")\n",
    "# print(data_array[0:10])\n",
    "\n",
    "# # 打印索引从 1,000,000 到 1,000,009 的数据\n",
    "# # 注意：确保 data_array 的长度足够大，否则可能会引发索引错误\n",
    "# print(\"\\n索引从 1,000,000 到 1,000,009 的数据:\")\n",
    "# print(data_array[719_990:720_000])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T14:04:16.129433Z",
     "iopub.status.busy": "2024-10-15T14:04:16.129073Z",
     "iopub.status.idle": "2024-10-15T14:04:16.331286Z",
     "shell.execute_reply": "2024-10-15T14:04:16.330629Z",
     "shell.execute_reply.started": "2024-10-15T14:04:16.129408Z"
    },
    "id": "1oD9yQb9g-Ov",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaen/miniconda3/envs/lastestorch/lib/python3.11/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------\n",
      "| epoch   1 | 27.05 s | train loss 34994.73695 | val loss 1395.32045 | lr 0.10000000 | r2 sklearn: 0.01620 | b, s, h: 0|\n",
      "----------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------\n",
      "| epoch   2 | 26.63 s | train loss 34679.19050 | val loss 1369.04172 | lr 0.09800000 | r2 sklearn: 0.03473 | b, s, h: 0|\n",
      "----------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------\n",
      "| epoch   3 | 26.64 s | train loss 34530.66041 | val loss 1366.06775 | lr 0.09604000 | r2 sklearn: 0.03682 | b, s, h: 0|\n",
      "----------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------\n",
      "| epoch   4 | 26.76 s | train loss 34435.52679 | val loss 1331.87783 | lr 0.09411920 | r2 sklearn: 0.06093 | b, s, h: 0|\n",
      "----------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------\n",
      "| epoch   5 | 31.19 s | train loss 34357.58856 | val loss 1292.26495 | lr 0.09223682 | r2 sklearn: 0.08886 | b, s, h: 0|\n",
      "----------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------\n",
      "| epoch   6 | 33.61 s | train loss 34137.29112 | val loss 1170.71551 | lr 0.09039208 | r2 sklearn: 0.17456 | b, s, h: 0|\n",
      "----------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------\n",
      "| epoch   7 | 26.77 s | train loss 33773.93333 | val loss 1120.61376 | lr 0.08858424 | r2 sklearn: 0.20989 | b, s, h: 0|\n",
      "----------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------\n",
      "| epoch   8 | 27.02 s | train loss 33469.70423 | val loss 1077.15152 | lr 0.08681255 | r2 sklearn: 0.24053 | b, s, h: 0|\n",
      "----------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------\n",
      "| epoch   9 | 27.23 s | train loss 33339.46005 | val loss 1049.98740 | lr 0.08507630 | r2 sklearn: 0.25968 | b, s, h: 0|\n",
      "----------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------\n",
      "| epoch  10 | 31.12 s | train loss 33254.73601 | val loss 1046.76134 | lr 0.08337478 | r2 sklearn: 0.26196 | b, s, h: 0|\n",
      "----------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------\n",
      "| epoch  11 | 31.10 s | train loss 33206.53276 | val loss 1034.21565 | lr 0.08170728 | r2 sklearn: 0.27080 | b, s, h: 0|\n",
      "----------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------\n",
      "| epoch  12 | 31.41 s | train loss 33204.06523 | val loss 1030.82042 | lr 0.08007314 | r2 sklearn: 0.27320 | b, s, h: 0|\n",
      "----------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------\n",
      "| epoch  13 | 31.38 s | train loss 33099.57282 | val loss 1034.88960 | lr 0.07847167 | r2 sklearn: 0.27033 | b, s, h: 0|\n",
      "----------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------\n",
      "| epoch  14 | 31.32 s | train loss 33679.61971 | val loss 1042.23391 | lr 0.07690224 | r2 sklearn: 0.26515 | b, s, h: 0|\n",
      "----------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------\n",
      "| epoch  15 | 31.18 s | train loss 33050.50723 | val loss 1052.25184 | lr 0.07536419 | r2 sklearn: 0.25809 | b, s, h: 0|\n",
      "----------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------\n",
      "| epoch  16 | 31.23 s | train loss 33030.89600 | val loss 1029.54771 | lr 0.07385691 | r2 sklearn: 0.27409 | b, s, h: 0|\n",
      "----------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------\n",
      "| epoch  17 | 31.19 s | train loss 33192.98191 | val loss 1030.75600 | lr 0.07237977 | r2 sklearn: 0.27324 | b, s, h: 0|\n",
      "----------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------\n",
      "| epoch  18 | 31.43 s | train loss 33231.66458 | val loss 1076.49628 | lr 0.07093218 | r2 sklearn: 0.24099 | b, s, h: 0|\n",
      "----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model_name = 'Transwiths4_tmp_1'\n",
    "\n",
    "save_path = os.path.join(f'/home/gaen/Documents/codespace-gaen/Ts-master/playround_models/{model_name}/training_details/HFTransformer/results_HFformer',\n",
    "                            str(int(time.time()))+'_results.csv')\n",
    "\n",
    "# save_path = f'/mnt/workspace/shell/tmp/{model_name}/training_details/HFTransformer/results_HFformer'\n",
    "# # save_path=None\n",
    "# save_path = f'/home/gaen/Documents/codespace-gaen/Simons/{model_name}/training_details/HFTransformer/results_HFformer'\n",
    "filepath = f'/home/gaen/Documents/codespace-gaen/Ts-master{model_name}/training_details/HFTransformer/results_HFformer/HFformer'\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "os.makedirs(filepath, exist_ok=True)\n",
    "\n",
    "forecast_history = 100\n",
    "epochs = 32\n",
    "batch_size = 256 #64 for linear decoder\n",
    "\n",
    "forecast_windows = [i for i in range(1,32)]\n",
    "\n",
    "for forecast_window in forecast_windows:\n",
    "    \n",
    "    # orderbook = augment_trade_data(agg_trade, lag=0, forecast_window=forecast_window)\n",
    "    orderbook = augment_trade_data(agg_trade, lag=0, forecast_window=forecast_window)\n",
    "    # total_orw = orderbook.shape[0]\n",
    "    # print(total_orw)\n",
    "    features = ['price', 'lag_return',\n",
    "                'bid1', 'bidqty1', 'bid2', 'bidqty2', 'bid3', 'bidqty3', 'bid4', 'bidqty4', 'bid5', 'bidqty5',\n",
    "                'bid6', 'bidqty6', 'bid7', 'bidqty7', 'bid8', 'bidqty8', 'bid9', 'bidqty9',\n",
    "                'ask1', 'askqty1', 'ask2', 'askqty2', 'ask3', 'askqty3', 'ask4', 'askqty4', 'ask5', 'askqty5',\n",
    "                'ask6', 'askqty6', 'ask7', 'askqty7', 'ask8', 'askqty8', 'ask9', 'askqty9']\n",
    "\n",
    "\n",
    "    split_index, data_x_train, data_y_train, data_x_val, data_y_val = prepare_data(np.array(orderbook[features][1_000_000:1_350_000]),\n",
    "                                                                                                                            np.array(agg_trade.datetime[899_999:1_000_000]),\n",
    "                                                                                                                            np.array(orderbook[features][60_000:60_600]),\n",
    "                                                                                                                            np.array(agg_trade.datetime[60_000:60_600]),\n",
    "                                                                                                                            config, lag=forecast_window, plot=False)\n",
    "\n",
    "    # data_x_train_shape = data_x_train.shape[1]\n",
    "    # data_y_train_shape = data_y_train.shape[1]\n",
    "    # data_x_val_shape = data_x_val.shape[1]\n",
    "    # data_y_val_shape = data_y_val.shape[1]\n",
    "    # print( data_x_train_shape , data_y_train_shape ,data_x_val_shape, data_y_val_shape)\n",
    "    train_loader = TimeSeriesDataset(data_x_train, data_y_train)\n",
    "    val_loader = TimeSeriesDataset(data_x_val, data_y_val)\n",
    "    test_loader = None\n",
    "\n",
    "    model_custom = S4Transformer(input_size=len(features), d_model=36,\n",
    "                 num_layers=3, output_size=1).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss(reduction='sum')\n",
    "    optimizer = optim.AdamW(model_custom.parameters(), lr=0.1, amsgrad=True)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "    warmup_scheduler = warmup.LinearWarmup(optimizer, warmup_period=1000)\n",
    "\n",
    "    trainer(model_custom, train_loader, val_loader, test_loader, [criterion], optimizer, scheduler, warmup_scheduler, epochs, batch_size=batch_size,\n",
    "        forecast_horizon=forecast_window, takes_target=False, plot_prediction=False, save_path=save_path, LAG=forecast_window)\n",
    "    \n",
    "    del data_x_train \n",
    "    del data_y_train\n",
    "    del data_x_val\n",
    "    del data_y_val\n",
    "\n",
    "    torch.save(model_custom, f'/home/gaen/Documents/codespace-gaen/Ts-master/playround_models/{model_name}/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
    "    print(f'Done with prediction len {forecast_window}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    date_train = 'all' \n",
    "    date_test = 'all'\n",
    "    drive = None\n",
    "    if drive:\n",
    "        agg_trade = pd.read_csv(config[\"paths\"][\"drive\"][\"agg_trade\"][\"train\"]+date_train+'/orderbook.csv')    \n",
    "        sys.path.append(config[\"paths\"][\"drive\"][\"utils\"])\n",
    "    else:\n",
    "        agg_trade = pd.read_csv(config[\"paths\"][\"local\"][\"agg_trade\"][\"train\"]+date_train+'/orderbook_agg_trade_dollarvol_drop_near_duplicate_price.csv')\n",
    "        agg_trade_test = pd.read_csv(config[\"paths\"][\"local\"][\"agg_trade\"][\"test\"]+date_test+'/orderbook_agg_trade_dollarvol_drop_near_duplicate_price.csv')\n",
    "    idx = 0\n",
    "    agg_trade['w_midprice'] = (agg_trade['ask1']*agg_trade['askqty1']+agg_trade['bid1']*agg_trade['bidqty1'])/(agg_trade['askqty1']+agg_trade['bidqty1'])\n",
    "\n",
    "    #agg_trade['price'] = agg_trade['w_midprice']\n",
    "    agg_trade_test = agg_trade[4_500_000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    save_path = os.path.join('./home/gaen/Documents/codespace-gaen/Simons/models_drop_duplicate_near/training_details/HFTransformer/results_HFformer',\n",
    "                                str(int(time.time()))+'_results.csv')\n",
    "\n",
    "    save_path = '/home/gaen/Documents/codespace-gaen/Simons/models_drop_duplicate_near/training_details/HFTransformer/results_HFformer'\n",
    "    # save_path=None\n",
    "\n",
    "    forecast_history = 100 \n",
    "    epochs = 16\n",
    "    batch_size = 300 #64 for linear decoder\n",
    "\n",
    "    forecast_windows = [i for i in range(1,31)]\n",
    "\n",
    "    for forecast_window in forecast_windows:\n",
    "        \n",
    "        orderbook = augment_trade_data(agg_trade, lag=0, forecast_window=forecast_window)\n",
    "\n",
    "        features = ['price', 'lag_return',\n",
    "                    'bid1', 'bidqty1', 'bid2', 'bidqty2', 'bid3', 'bidqty3', 'bid4', 'bidqty4', 'bid5', 'bidqty5',\n",
    "                    'bid6', 'bidqty6', 'bid7', 'bidqty7', 'bid8', 'bidqty8', 'bid9', 'bidqty9',\n",
    "                    'ask1', 'askqty1', 'ask2', 'askqty2', 'ask3', 'askqty3', 'ask4', 'askqty4', 'ask5', 'askqty5',\n",
    "                    'ask6', 'askqty6', 'ask7', 'askqty7', 'ask8', 'askqty8', 'ask9', 'askqty9']\n",
    "\n",
    "        split_index, data_x_train, data_y_train, data_x_val, data_y_val = prepare_data(np.array(orderbook[features][1_000_000-700000:1_720_000-700000]),\n",
    "                                                                                                                                np.array(agg_trade.datetime[2_005_000-1200000:2_006_000-1200000]),\n",
    "                                                                                                                                np.array(orderbook[features][60_000:60_600]),\n",
    "                                                                                                                                np.array(agg_trade.datetime[60_000:60_600]),\n",
    "                                                                                                                                config, lag=forecast_window, plot=False)\n",
    "\n",
    "\n",
    "        train_loader = TimeSeriesDataset(data_x_train, data_y_train)\n",
    "        val_loader = TimeSeriesDataset(data_x_val, data_y_val)\n",
    "        test_loader = None\n",
    "\n",
    "        model_custom = HFformer(n_time_series=len(features), seq_len=forecast_history, output_seq_len=1, d_model=36,\n",
    "                    n_heads=6, n_layers_encoder=2, dropout=0.3, output_dim=1, forward_dim=64, use_mask=True).to(device)\n",
    "\n",
    "        criterion = nn.MSELoss(reduction='sum')\n",
    "        optimizer = optim.AdamW(model_custom.parameters(), lr=0.1, amsgrad=True)\n",
    "        scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "        warmup_scheduler = warmup.LinearWarmup(optimizer, warmup_period=1000)\n",
    "\n",
    "        trainer(model_custom, train_loader, val_loader, test_loader, [criterion], optimizer, scheduler, warmup_scheduler, epochs, batch_size=batch_size,\n",
    "            forecast_horizon=forecast_window, takes_target=False, plot_prediction=False, save_path=save_path, LAG=forecast_window)\n",
    "        \n",
    "        del data_x_train \n",
    "        del data_y_train\n",
    "        del data_x_val\n",
    "        del data_y_val\n",
    "\n",
    "        torch.save(model_custom, f'./models_drop_duplicate_near/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
    "        print(f'Done with prediction len {forecast_window}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRVCqRHngARx"
   },
   "source": [
    "## Forecast Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "QwYi2KUoQ61u"
   },
   "outputs": [],
   "source": [
    "def strategy_evaluator(true, pred, weighted=False):\n",
    "    '''\n",
    "    Evaluates trading strategy based on correct buys and sells.\n",
    "    '''\n",
    "    total_buys, total_sells, total_holds = np.sum(true>0), np.sum(true<0), np.sum(true==0)\n",
    "    total_correct_buys, total_correct_sells, total_correct_holds = 0, 0, 0\n",
    "    for idx in range(len(true)):\n",
    "        if true[idx] > 0 and pred[idx] > 0:\n",
    "            total_correct_buys += 1\n",
    "        elif true[idx] < 0 and pred[idx] < 0:\n",
    "            total_correct_sells += 1\n",
    "        elif true[idx] == 0 and pred[idx] == 0:\n",
    "            total_correct_holds += 1\n",
    "    total_correct_buys_r, total_correct_sells_r, total_correct_holds_r = (total_correct_buys/total_buys),(total_correct_sells/total_sells),(total_correct_holds/total_holds)\n",
    "    total_correct_trades = (total_correct_buys+total_correct_sells+total_correct_holds)/(total_buys+total_sells+total_holds)\n",
    "    return total_buys, total_correct_buys, total_sells, total_correct_sells, total_holds, total_correct_holds\n",
    "\n",
    "\n",
    "def forecast_evaluator(test_loader, model, criterion, forecast_horizon=1, device=device, num_targets=1, save_path=None):\n",
    "    '''\n",
    "    Outputs evaluation metrics.\n",
    "    '''\n",
    "    test_data_loader = DataLoader(test_loader, batch_size=128, shuffle=False, sampler=None, batch_sampler=None, num_workers=6)\n",
    "    loss, pred, true = forecast(test_data_loader, model, criterion, forecast_horizon=1, device=device, num_targets=1)\n",
    "    pred, true = pred.cpu().numpy(), true.cpu().numpy()\n",
    "\n",
    "    r2 = r2_score(true, pred)\n",
    "    strategy_results = strategy_evaluator(true, pred)\n",
    "    \n",
    "    if save_path:\n",
    "        results = {\n",
    "                'model': 'Transencwithlineardec',\n",
    "                'pred_len': forecast_horizon,\n",
    "                'test_loss': loss,\n",
    "                'r2_val_sklearn': r2,\n",
    "                'correct_buys': strategy_results[1],\n",
    "                'total_buys':  strategy_results[0],\n",
    "                'correct_sells': strategy_results[3],\n",
    "                'total_sells': strategy_results[2],\n",
    "                'correct_holds': strategy_results[5],\n",
    "                'total_holds': strategy_results[4],\n",
    "        }\n",
    "        os.makedirs(save_path_model, exist_ok=True)\n",
    "      \n",
    "        df.to_csv(save_path, mode='a', header=not os.path.exists(save_path), index=False)\n",
    "\n",
    "    print(f'| test loss {loss} | b, cb, s, cs, h, ch: {strategy_results} |')\n",
    "\n",
    "    return pred, true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djC9UZA6gARy"
   },
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "UeQr6KHN1HDZ"
   },
   "outputs": [],
   "source": [
    "date_train = 'all' \n",
    "date_test = 'all'\n",
    "drive  = None\n",
    "if drive:\n",
    "    agg_trade = pd.read_csv(config[\"paths\"][\"drive\"][\"agg_trade\"][\"train\"]+date_train+'/orderbook.csv')    \n",
    "    sys.path.append(config[\"paths\"][\"drive\"][\"utils\"])\n",
    "else:\n",
    "    agg_trade = pd.read_csv(config[\"paths\"][\"local\"][\"agg_trade\"][\"train\"]+date_train+'/orderbook_agg_trade_dollarvol.csv')\n",
    "    agg_trade_test = pd.read_csv(config[\"paths\"][\"local\"][\"agg_trade\"][\"test\"]+date_test+'/orderbook_agg_trade_dollarvol.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281482, 43)\n"
     ]
    }
   ],
   "source": [
    "agg_trade_test = agg_trade[1_200_000:]\n",
    "print(agg_trade_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "S-vAZLp5gARy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281480, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([79])) that is different to the input size (torch.Size([79, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 1332352.4474906921 | b, cb, s, cs, h, ch: (np.int64(99814), 82760, np.int64(103135), 84048, np.int64(22154), 0) |\n",
      "Done with prediction len 1.\n",
      "(281479, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([77])) that is different to the input size (torch.Size([77, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 1863647.774682045 | b, cb, s, cs, h, ch: (np.int64(103582), 86683, np.int64(105646), 87535, np.int64(15873), 0) |\n",
      "Done with prediction len 2.\n",
      "(281478, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([76])) that is different to the input size (torch.Size([76, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 1843596.1167755127 | b, cb, s, cs, h, ch: (np.int64(105719), 89502, np.int64(106801), 88454, np.int64(12580), 0) |\n",
      "Done with prediction len 3.\n",
      "(281477, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([74])) that is different to the input size (torch.Size([74, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 1959704.1126847267 | b, cb, s, cs, h, ch: (np.int64(107154), 90156, np.int64(107453), 88711, np.int64(10491), 0) |\n",
      "Done with prediction len 4.\n",
      "(281476, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([72])) that is different to the input size (torch.Size([72, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 2132914.295627594 | b, cb, s, cs, h, ch: (np.int64(108209), 89041, np.int64(107928), 88571, np.int64(8959), 0) |\n",
      "Done with prediction len 5.\n",
      "(281475, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([71])) that is different to the input size (torch.Size([71, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 2210494.969649315 | b, cb, s, cs, h, ch: (np.int64(108947), 88138, np.int64(108164), 88331, np.int64(7984), 0) |\n",
      "Done with prediction len 6.\n",
      "(281474, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([69])) that is different to the input size (torch.Size([69, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 2384155.649002075 | b, cb, s, cs, h, ch: (np.int64(109437), 87154, np.int64(108455), 88684, np.int64(7201), 0) |\n",
      "Done with prediction len 7.\n",
      "(281473, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([68])) that is different to the input size (torch.Size([68, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 2501408.765411377 | b, cb, s, cs, h, ch: (np.int64(109922), 87783, np.int64(108645), 87093, np.int64(6525), 0) |\n",
      "Done with prediction len 8.\n",
      "(281472, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([66])) that is different to the input size (torch.Size([66, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 2617375.8036060333 | b, cb, s, cs, h, ch: (np.int64(110346), 88125, np.int64(108758), 86083, np.int64(5986), 0) |\n",
      "Done with prediction len 9.\n",
      "(281471, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 2700808.742969513 | b, cb, s, cs, h, ch: (np.int64(110665), 88714, np.int64(108836), 84362, np.int64(5587), 0) |\n",
      "Done with prediction len 10.\n",
      "(281470, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([63])) that is different to the input size (torch.Size([63, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 2797883.6235809326 | b, cb, s, cs, h, ch: (np.int64(111021), 87271, np.int64(108934), 83516, np.int64(5132), 0) |\n",
      "Done with prediction len 11.\n",
      "(281469, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([61])) that is different to the input size (torch.Size([61, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 2863783.948059082 | b, cb, s, cs, h, ch: (np.int64(111140), 85098, np.int64(109031), 84180, np.int64(4914), 0) |\n",
      "Done with prediction len 12.\n",
      "(281468, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([60])) that is different to the input size (torch.Size([60, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 2926648.3179035187 | b, cb, s, cs, h, ch: (np.int64(111348), 85855, np.int64(109150), 81571, np.int64(4586), 0) |\n",
      "Done with prediction len 13.\n",
      "(281467, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([58])) that is different to the input size (torch.Size([58, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 2938133.6167240143 | b, cb, s, cs, h, ch: (np.int64(111538), 83606, np.int64(109199), 82539, np.int64(4345), 0) |\n",
      "Done with prediction len 14.\n",
      "(281466, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 3022370.5741386414 | b, cb, s, cs, h, ch: (np.int64(111658), 83681, np.int64(109254), 80556, np.int64(4168), 0) |\n",
      "Done with prediction len 15.\n",
      "(281465, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([55])) that is different to the input size (torch.Size([55, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 3068906.5960998535 | b, cb, s, cs, h, ch: (np.int64(111859), 83467, np.int64(109250), 80455, np.int64(3970), 0) |\n",
      "Done with prediction len 16.\n",
      "(281464, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([53])) that is different to the input size (torch.Size([53, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 3236092.3521871567 | b, cb, s, cs, h, ch: (np.int64(112073), 80858, np.int64(109222), 79458, np.int64(3782), 0) |\n",
      "Done with prediction len 17.\n",
      "(281463, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([52])) that is different to the input size (torch.Size([52, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 3177264.043231964 | b, cb, s, cs, h, ch: (np.int64(112179), 82351, np.int64(109301), 79090, np.int64(3596), 0) |\n",
      "Done with prediction len 18.\n",
      "(281462, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([50])) that is different to the input size (torch.Size([50, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 3324389.24905777 | b, cb, s, cs, h, ch: (np.int64(112358), 81454, np.int64(109271), 76200, np.int64(3445), 0) |\n",
      "Done with prediction len 19.\n",
      "(281461, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([48])) that is different to the input size (torch.Size([48, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 3364001.519472122 | b, cb, s, cs, h, ch: (np.int64(112396), 81506, np.int64(109309), 77022, np.int64(3367), 0) |\n",
      "Done with prediction len 20.\n",
      "(281460, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([47])) that is different to the input size (torch.Size([47, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 3442012.4794006348 | b, cb, s, cs, h, ch: (np.int64(112405), 81712, np.int64(109450), 75847, np.int64(3216), 0) |\n",
      "Done with prediction len 21.\n",
      "(281459, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([45])) that is different to the input size (torch.Size([45, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 3338813.7320041656 | b, cb, s, cs, h, ch: (np.int64(112405), 80095, np.int64(109549), 76362, np.int64(3115), 0) |\n",
      "Done with prediction len 22.\n",
      "(281458, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([44])) that is different to the input size (torch.Size([44, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 3406507.9989204407 | b, cb, s, cs, h, ch: (np.int64(112423), 79717, np.int64(109639), 75406, np.int64(3006), 0) |\n",
      "Done with prediction len 23.\n",
      "(281457, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([42])) that is different to the input size (torch.Size([42, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 3371869.5652484894 | b, cb, s, cs, h, ch: (np.int64(112418), 78686, np.int64(109745), 74672, np.int64(2903), 0) |\n",
      "Done with prediction len 24.\n",
      "(281456, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([40])) that is different to the input size (torch.Size([40, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 3515341.960006714 | b, cb, s, cs, h, ch: (np.int64(112441), 80450, np.int64(109795), 74638, np.int64(2828), 0) |\n",
      "Done with prediction len 25.\n",
      "(281455, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([39])) that is different to the input size (torch.Size([39, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 3502829.6949882507 | b, cb, s, cs, h, ch: (np.int64(112335), 76485, np.int64(109939), 76387, np.int64(2789), 0) |\n",
      "Done with prediction len 26.\n",
      "(281454, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([37])) that is different to the input size (torch.Size([37, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 3530304.6581172943 | b, cb, s, cs, h, ch: (np.int64(112398), 76854, np.int64(110009), 76983, np.int64(2654), 0) |\n",
      "Done with prediction len 27.\n",
      "(281453, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([36])) that is different to the input size (torch.Size([36, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 3582732.0289669037 | b, cb, s, cs, h, ch: (np.int64(112403), 75467, np.int64(110069), 76061, np.int64(2588), 0) |\n",
      "Done with prediction len 28.\n",
      "(281452, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([34])) that is different to the input size (torch.Size([34, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 3608577.380016327 | b, cb, s, cs, h, ch: (np.int64(112420), 75424, np.int64(110133), 74819, np.int64(2505), 0) |\n",
      "Done with prediction len 29.\n",
      "(281451, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 3582746.993657589 | b, cb, s, cs, h, ch: (np.int64(112350), 76958, np.int64(110202), 74194, np.int64(2504), 0) |\n",
      "Done with prediction len 30.\n",
      "(281450, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8121/2918264227.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
      "/tmp/ipykernel_8121/3813266209.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/software/anaconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([31])) that is different to the input size (torch.Size([31, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss 3602795.6707611084 | b, cb, s, cs, h, ch: (np.int64(112370), 76615, np.int64(110259), 73693, np.int64(2426), 0) |\n",
      "Done with prediction len 31.\n"
     ]
    }
   ],
   "source": [
    "save_path = os.path.join('/mnt/workspace/shell/models/training_details/HFTransformer/results_HFformer_tmp',\n",
    "                            str(int(time.time()))+'_forecasting_results.csv')\n",
    "\n",
    "# save_path = None\n",
    "\n",
    "save_path_results = os.path.join('/mnt/workspace/shell/models/training_details/HFTransformer/results_HFformer_tmp',\n",
    "                            str(int(time.time()))+'_list_results.pkl')\n",
    "\n",
    "save_path_model = os.path.join('/mnt/workspace/shell/models/training_details/HFTransformer/results_HFformer_tmp',str(int(time.time()))+'_model.pth')\n",
    "\n",
    "forecast_history = 100 \n",
    "batch_size = 256 #64 for linear decoder\n",
    "\n",
    "forecast_windows = [i for i in range(1,32)]\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for forecast_window in forecast_windows:\n",
    "    \n",
    "    orderbook = augment_trade_data(agg_trade_test, lag=0, forecast_window=forecast_window)\n",
    "\n",
    "    features = ['price', 'lag_return',\n",
    "                'bid1', 'bidqty1', 'bid2', 'bidqty2', 'bid3', 'bidqty3', 'bid4', 'bidqty4', 'bid5', 'bidqty5',\n",
    "                'bid6', 'bidqty6', 'bid7', 'bidqty7', 'bid8', 'bidqty8', 'bid9', 'bidqty9',\n",
    "                'ask1', 'askqty1', 'ask2', 'askqty2', 'ask3', 'askqty3', 'ask4', 'askqty4', 'ask5', 'askqty5',\n",
    "                'ask6', 'askqty6', 'ask7', 'askqty7', 'ask8', 'askqty8', 'ask9', 'askqty9']\n",
    "    print(orderbook[features].shape)\n",
    "\n",
    "    split_index, data_x_train, data_y_train, data_x_val, data_y_val = prepare_data(np.array(orderbook[features][:]),\n",
    "                                                                                    np.array(agg_trade.datetime[2_005_000-500000:2_006_00-5000000]),\n",
    "                                                                                    np.array(orderbook[features][60_000:60_600]),\n",
    "                                                                                    np.array(agg_trade.datetime[60_000:60_600]),\n",
    "                                                                                    config, lag=forecast_window, plot=True)\n",
    "\n",
    "    test_loader = TimeSeriesDataset(data_x_train, data_y_train)\n",
    "\n",
    "    model = torch.load(f'/mnt/workspace/shell/tmp/HFfMODELsept10test_tmp_1/transformer_enclinear_forecasting_FINAL_horizon_{forecast_window}.pt')\n",
    "    criterion = nn.MSELoss(reduction='sum')\n",
    "\n",
    "    pred, true = forecast_evaluator(test_loader, model, [criterion], forecast_horizon=forecast_window, device=device, num_targets=1, save_path=save_path)\n",
    "    \n",
    "    predictions.append((pred, true))\n",
    "\n",
    "    print(f'Done with prediction len {forecast_window}.')\n",
    "\n",
    "with open(save_path_results, 'wb') as f:\n",
    "    pickle.dump(predictions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "7_HFformerv2.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "lastestorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
